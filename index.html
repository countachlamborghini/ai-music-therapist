<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AI Music Therapist</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.js" id="faceapi-script"></script>
  <style>
    body { font-family: sans-serif; text-align: center; background: #f0f0f0; }
    video { margin-top: 20px; border: 2px solid #444; border-radius: 10px; }
    #status { margin-top: 20px; font-size: 1.2em; }
  </style>
</head>
<body>
  <h1>AI Music Therapist for Autism</h1>
  <video id="video" width="640" height="480" autoplay muted></video>
  <div id="status">Initializing...</div>

  <script>
    console.log('Script started');

    const video = document.getElementById('video');
    const statusDiv = document.getElementById('status');

    let currentAudio = new Audio('https://cdn.pixabay.com/download/audio/2022/03/15/audio_a35b212f21.mp3');
    currentAudio.loop = true;
    currentAudio.volume = 0.5;

    const FREQUENCIES = {
      happy: 'https://cdn.pixabay.com/download/audio/2022/03/15/audio_fce1d543e6.mp3',
      sad: 'https://cdn.pixabay.com/download/audio/2022/03/15/audio_282a7e4626.mp3',
      angry: 'https://cdn.pixabay.com/download/audio/2022/03/15/audio_282a7e4626.mp3',
      neutral: 'https://cdn.pixabay.com/download/audio/2022/03/15/audio_a35b212f21.mp3',
      surprised: 'https://cdn.pixabay.com/download/audio/2022/03/15/audio_fce1d543e6.mp3',
      fearful: 'https://cdn.pixabay.com/download/audio/2022/03/15/audio_282a7e4626.mp3',
      disgusted: 'https://cdn.pixabay.com/download/audio/2022/03/15/audio_282a7e4626.mp3'
    };

    async function changeMusic(emotion) {
      const url = FREQUENCIES[emotion] || FREQUENCIES['neutral'];
      const newAudio = new Audio(url);
      newAudio.loop = true;
      newAudio.volume = 0.5;
      currentAudio.pause();
      currentAudio = newAudio;
      currentAudio.play();
      statusDiv.textContent = `Emotion: ${emotion} | Playing frequency for mood`;
    }

    console.log('About to load models');
    statusDiv.textContent = 'Loading models...';

    async function loadModels() {
      try {
        // Debug: Check if faceapi is defined
        if (typeof faceapi === 'undefined') {
          throw new Error('faceapi is not defined');
        }
        console.log('faceapi is defined:', faceapi);
        console.log('faceapi.nets:', faceapi.nets);

        const modelBaseUrl = 'https://countachlamborghini.github.io/ai-music-therapist/models';

        console.log('Loading tinyFaceDetector from:', modelBaseUrl);
        await faceapi.nets.tinyFaceDetector.loadFromUri(modelBaseUrl);
        console.log('tinyFaceDetector loaded');
        statusDiv.textContent = 'tinyFaceDetector loaded, loading faceExpressionNet...';

        console.log('Loading faceExpressionNet from:', modelBaseUrl);
        await faceapi.nets.faceExpressionNet.loadFromUri(modelBaseUrl);
        console.log('faceExpressionNet loaded');
        statusDiv.textContent = 'Models loaded, starting webcam...';

        startVideo();
      } catch (err) {
        console.error('Model loading failed:', err);
        statusDiv.textContent = 'Failed to load models: ' + err.message + '. Check console.';
      }
    }

    // Wait for the face-api.js script to load before calling loadModels
    const faceapiScript = document.getElementById('faceapi-script');
    faceapiScript.onload = () => {
      console.log('face-api.js script loaded');
      loadModels();
    };
    faceapiScript.onerror = () => {
      console.error('Failed to load face-api.js script');
      statusDiv.textContent = 'Error: Failed to load face-api.js script';
    };

    function startVideo() {
      navigator.mediaDevices.getUserMedia({ video: {} })
        .then(stream => {
          video.srcObject = stream;
          console.log('Webcam started');
          statusDiv.textContent = 'Webcam started, detecting emotions...';
        })
        .catch(err => {
          console.error('Camera error:', err);
          statusDiv.textContent = `Camera access failed: ${err.message}`;
        });
    }

    video.addEventListener('play', () => {
      console.log('Video playing');
      setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();
        if (detections.length > 0) {
          const expr = detections[0].expressions;
          const topEmotion = Object.entries(expr).reduce((a, b) => a[1] > b[1] ? a : b)[0];
          changeMusic(topEmotion);
        } else {
          statusDiv.textContent = 'No face detected';
        }
      }, 5000);
    });
  </script>
</body>
</html>
